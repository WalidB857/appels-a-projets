# AAP-Watch ‚Äî Instructions Copilot

## üéØ Contexte du projet

**AAP-Watch** est un agr√©gateur d'Appels √† Projets (AAP) destin√© aux associations (ESS, solidarit√©, inclusion).

### Probl√®me r√©solu
La veille sur les AAP est chronophage car :
- Sources dispers√©es (collectivit√©s, fondations, agr√©gateurs)
- Pas de centralisation ni d'API unifi√©e
- Formats h√©t√©rog√®nes
- Risque de rater des deadlines

### Objectif
Automatiser la collecte, normalisation et alerting des AAP pertinents pour les associations.

---

## üèóÔ∏è Architecture

### Stack technique
- **Langage** : Python 3.12+
- **Package manager** : uv
- **Scraping HTML** : BeautifulSoup + requests
- **Parsing RSS** : feedparser
- **LLM** : Gemini Flash (extraction structur√©e)
- **Storage** : Notion API (MVP)
- **Orchestration** : GitHub Actions (cron)
- **Alertes** : Telegram Bot

### Structure du projet
```
appels-a-projets/
‚îú‚îÄ‚îÄ appels_a_projets/
‚îÇ   ‚îú‚îÄ‚îÄ connectors/          # Connecteurs par source
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carenews.py      # Scraper HTML Carenews
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iledefrance_opendata.py  # API IDF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rss_generic.py   # Parser RSS g√©n√©rique
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Mod√®les de donn√©es (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ processing/          # Normalisation, d√©duplication
‚îÇ   ‚îú‚îÄ‚îÄ storage/             # Connecteurs storage (Notion, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ alerting/            # Notifications (Telegram, email)
‚îú‚îÄ‚îÄ data/                    # Donn√©es locales (dev/debug)
‚îú‚îÄ‚îÄ docs/                    # Documentation & specs
‚îú‚îÄ‚îÄ tests/                   # Tests unitaires et int√©gration
‚îî‚îÄ‚îÄ .github/workflows/       # GitHub Actions (cron jobs)
```

---

## üìä Mod√®le de donn√©es AAP

Sch√©ma normalis√© pour tous les AAP, quelle que soit la source :

```python
class AAP(BaseModel):
    id: str                          # UUID
    titre: str
    organisme: str
    date_publication: date | None
    date_limite: date | None
    categories: list[str]            # Taxonomie fixe (filtrage)
    tags: list[str]                  # Tags libres (LLM)
    perimetre_geo: str | None
    public_cible: list[str]          # ["associations", "ESUS", ...]
    montant_min: float | None
    montant_max: float | None
    url_source: str
    url_candidature: str | None
    resume: str                      # Max 300 chars
    source_id: str                   # Identifiant source
    created_at: datetime
    fingerprint: str                 # hash(titre+organisme+date_limite)
```

### Cat√©gories (taxonomie fixe)
- `insertion-emploi`
- `education-jeunesse`
- `sante-handicap`
- `culture-sport`
- `environnement-transition`
- `solidarite-inclusion`
- `vie-associative`
- `numerique`
- `autre`

---

## üîå Sources de donn√©es (MVP)

| Source | Type | M√©thode | Priorit√© |
|--------|------|---------|----------|
| Carenews | Agr√©gateur | HTML scraping | P0 |
| IDF OpenData | API | REST API | P0 |
| Paris.fr | Institutionnel | HTML scraping | P1 |
| Profession Banlieue | Centre ressources | RSS | P1 |
| DRIEETS IDF | Gouv | RSS | P2 |

### URLs des sources
```
# P0
https://www.carenews.com/appels_a_projets
https://data.iledefrance.fr/explore/dataset/aides-appels-a-projets/api/

# P1
https://www.paris.fr/pages/repondre-a-un-appel-a-projets-5412
https://www.professionbanlieue.org/Appels-a-projets-Appel-a-manifestation-d-interet
```

---

## üõ†Ô∏è Conventions de d√©veloppement

### Style de code
- Python moderne (3.12+) : type hints, match statements, f-strings
- Formatage : ruff (format + lint)
- Validation : Pydantic v2 pour les mod√®les
- Async : utiliser `httpx` pour les requ√™tes si besoin de parall√©lisme

### Patterns pour les connecteurs

Chaque connecteur doit :
1. H√©riter d'une classe `BaseConnector`
2. Impl√©menter `fetch_raw()` ‚Üí donn√©es brutes
3. Impl√©menter `parse(raw_data)` ‚Üí liste d'AAP normalis√©s
4. G√©rer ses propres erreurs et logging
5. Respecter les rate limits

```python
class BaseConnector(ABC):
    source_id: str
    source_name: str
    
    @abstractmethod
    def fetch_raw(self) -> Any:
        """R√©cup√®re les donn√©es brutes de la source"""
        pass
    
    @abstractmethod
    def parse(self, raw_data: Any) -> list[AAP]:
        """Parse et normalise les donn√©es en AAP"""
        pass
    
    def run(self) -> list[AAP]:
        """Ex√©cute le pipeline complet"""
        raw = self.fetch_raw()
        return self.parse(raw)
```

### Gestion des erreurs
- Logger toutes les erreurs avec contexte (source, URL, timestamp)
- Ne jamais crasher le pipeline complet si une source √©choue
- Retry avec backoff exponentiel pour les erreurs r√©seau

### Tests
- Un fichier de test par connecteur
- Fixtures avec des exemples de HTML/JSON r√©els (anonymis√©s si besoin)
- Mocks pour les appels r√©seau dans les tests unitaires

---

## üöÄ Commandes utiles

```bash
# Environnement
uv sync                          # Installer les d√©pendances
source .venv/bin/activate        # Activer l'environnement

# D√©veloppement
uv run python -m pytest          # Lancer les tests
uv run ruff check .              # Linter
uv run ruff format .             # Formatter

# Connecteurs (exemples)
uv run python -m appels_a_projets.connectors.carenews
uv run python -m appels_a_projets.connectors.iledefrance_opendata
```

---

## üìù Notes importantes

1. **Approche pragmatique** : "D√©j√† fetch les donn√©es, apr√®s tu verras ton mod√®le"
2. **Connecteurs cibl√©s** : Pas d'agent RL/adaptatif pour le MVP, connecteurs d√©di√©s par source
3. **D√©duplication** : `fingerprint = hash(titre + organisme + date_limite)`
4. **Co√ªt ma√Ætris√©** : < $10/mois (GitHub Actions gratuit, Gemini Flash ~$1-5)

---

## üë• √âquipe

- **Younes Ajeddig** : D√©veloppement, scraping
- **Walid Becherif** : Architecture, API IDF
