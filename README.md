# AAP-Watch ğŸ””

> AgrÃ©gateur d'Appels Ã  Projets pour associations (ESS, solidaritÃ©, inclusion)

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/badge/package%20manager-uv-blueviolet)](https://docs.astral.sh/uv/)

## ğŸ¯ ProblÃ¨me rÃ©solu

La veille sur les appels Ã  projets (AAP) est chronophage pour les associations :
- Sources dispersÃ©es (collectivitÃ©s, fondations, agrÃ©gateurs)
- Pas de centralisation ni d'API unifiÃ©e
- Formats hÃ©tÃ©rogÃ¨nes
- Risque de rater des deadlines

**AAP-Watch** automatise la collecte, normalisation et alerting des AAP pertinents.

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) (gestionnaire de packages)

```bash
# Installer uv (si pas dÃ©jÃ  installÃ©)
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Setup du projet

```bash
# Cloner le repo
git clone https://github.com/WalidB857/appels-a-projets.git
cd appels-a-projets

# CrÃ©er l'environnement et installer les dÃ©pendances
uv sync

# Copier et configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos credentials Airtable
```

## ğŸš€ Utilisation

### Scripts disponibles

```bash
# Tester le modÃ¨le de donnÃ©es (charge 443 AAPs)
uv run python scripts/test_model.py

# Exporter les AAPs actifs en CSV
uv run python scripts/export_csv.py --active-only

# Afficher le schÃ©ma Airtable recommandÃ©
uv run python scripts/setup_airtable.py --schema

# Tester la connexion Airtable
uv run python scripts/setup_airtable.py --test
```

### Utiliser dans du code Python

```python
from appels_a_projets.connectors import CarenewsConnector, IleDeFranceConnector
from appels_a_projets.processing import normalize_all
from appels_a_projets.models import Category, EligibiliteType

# 1. Fetch et normaliser les donnÃ©es
carenews = CarenewsConnector()
collection = normalize_all(carenews.run(), "Carenews", "https://www.carenews.com")

# 2. Fusionner plusieurs sources
idf = IleDeFranceConnector()
collection.merge(normalize_all(idf.run(), "IDF", "https://data.iledefrance.fr"))

# 3. Filtrer
actifs = collection.filter_active()
assos = actifs.filter_by_eligibilite(EligibiliteType.ASSOCIATIONS)
solidarite = assos.filter_by_category(Category.SOLIDARITE_INCLUSION)
urgents = solidarite.filter_by_urgence("urgent", "proche")

# 4. Statistiques
print(collection.stats())

# 5. Exporter
collection.to_csv("export.csv")
collection.to_json("export.json")
df = collection.to_dataframe()
```

### Explorer les donnÃ©es

```bash
# Lancer Jupyter pour les notebooks d'exploration
uv run jupyter notebook
```

## ğŸ“ Structure du projet

```
appels-a-projets/
â”œâ”€â”€ appels_a_projets/
â”‚   â”œâ”€â”€ connectors/              # Connecteurs par source
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseConnector + RawAAP
â”‚   â”‚   â”œâ”€â”€ carenews.py          # Scraper HTML Carenews
â”‚   â”‚   â”œâ”€â”€ iledefrance_opendata.py  # API IDF
â”‚   â”‚   â””â”€â”€ airtable_connector.py    # Upload Airtable
â”‚   â”œâ”€â”€ models/                  # ModÃ¨les de donnÃ©es (Pydantic)
â”‚   â”‚   â””â”€â”€ aap.py               # AAP, Category, EligibiliteType...
â”‚   â”œâ”€â”€ processing/              # Normalisation, dÃ©duplication
â”‚   â”‚   â””â”€â”€ normalizer.py        # RawAAP â†’ AAP (avec infÃ©rence)
â”‚   â””â”€â”€ jobs/                    # Notebooks d'exploration/enrichissement
â”‚       â”œâ”€â”€ inspect_idf.ipynb
â”‚       â”œâ”€â”€ scrape_paris.ipynb
â”‚       â””â”€â”€ enrichment_*.ipynb   # Enrichissement LLM
â”œâ”€â”€ scripts/                     # Scripts utilitaires
â”‚   â”œâ”€â”€ test_model.py
â”‚   â”œâ”€â”€ export_csv.py
â”‚   â””â”€â”€ setup_airtable.py
â”œâ”€â”€ data/                        # DonnÃ©es extraites
â”œâ”€â”€ docs/                        # Documentation & specs
â”œâ”€â”€ .env.example                 # Template variables d'environnement
â”œâ”€â”€ pyproject.toml               # Config projet (uv/pip)
â””â”€â”€ uv.lock                      # Lock file uv
```

## ğŸ”Œ Sources de donnÃ©es

| Source | Type | MÃ©thode | Status | AAPs |
|--------|------|---------|--------|------|
| Carenews | AgrÃ©gateur | HTML scraping | âœ… Done | ~100 |
| IDF OpenData | API | REST API | âœ… Done | ~343 |
| Paris.fr | Institutionnel | HTML + PDF + LLM | ğŸ”„ En cours | - |
| Profession Banlieue | Centre ressources | RSS | ğŸ”œ Ã€ faire | - |
| DRIEETS IDF | Gouv | RSS | ğŸ”œ Ã€ faire | - |

## ğŸ“Š ModÃ¨le de donnÃ©es

### Taxonomies

**Categories (12):**
`insertion-emploi` Â· `education-jeunesse` Â· `sante-handicap` Â· `culture-sport` Â· `environnement-transition` Â· `solidarite-inclusion` Â· `vie-associative` Â· `numerique` Â· `economie-ess` Â· `logement-urbanisme` Â· `mobilite-transport` Â· `autre`

**Ã‰ligibilitÃ© (7):**
`associations` Â· `collectivites` Â· `etablissements` Â· `entreprises` Â· `professionnels` Â· `particuliers` Â· `autre`

**PÃ©rimÃ¨tre (6):**
`local` Â· `departemental` Â· `regional` Â· `national` Â· `europeen` Â· `international`

**Urgence (5):**
`urgent` (â‰¤7j) Â· `proche` (â‰¤30j) Â· `confortable` (>30j) Â· `permanent` Â· `expire`

### SchÃ©ma AAP

```python
AAP(
    # IdentitÃ©
    id="uuid",
    titre="Concours 2026 de La France s'engage",
    url_source="https://...",
    source=Source(id="carenews", name="Carenews"),
    
    # Dates
    date_publication=date(2025, 12, 24),
    date_limite=date(2026, 1, 29),
    
    # Classification
    categories=[Category.SOLIDARITE_INCLUSION],
    tags=["ESS", "innovation sociale"],
    eligibilite=[EligibiliteType.ASSOCIATIONS],
    
    # GÃ©ographie
    perimetre_niveau=Perimetre.NATIONAL,
    perimetre_geo="France",
    
    # Financement
    montant_min=10000,
    montant_max=300000,
    
    # Computed fields
    fingerprint="abc123...",   # DÃ©duplication
    is_active=True,
    days_remaining=26,
    urgence="proche",
    statut=StatutAAP.OUVERT,
)
```

## ğŸ’¾ Stockage Airtable

La base Airtable contient **200+ AAPs actifs** avec tous les champs du modÃ¨le.

```bash
# VÃ©rifier la connexion
uv run python scripts/setup_airtable.py --test

# Exporter et importer de nouvelles donnÃ©es
uv run python scripts/export_csv.py --active-only
# Puis importer le CSV dans Airtable
```

## ğŸ› ï¸ DÃ©veloppement

### Commandes utiles

```bash
# Installer les dÃ©pendances (y compris dev)
uv sync

# Ajouter une dÃ©pendance
uv add <package>

# Lancer les tests
uv run pytest

# Linter/Formatter
uv run ruff check .
uv run ruff format .
```

### Branches

- `main` : Version stable
- `dev` : DÃ©veloppement actif
- `feature/*` : Nouvelles fonctionnalitÃ©s

## ğŸ—ºï¸ Roadmap

### âœ… Phase 0 : POC (Done)

- [x] Scraper Carenews (HTML) â†’ ~100 AAPs
- [x] Connecteur API IDF OpenData â†’ ~343 AAPs
- [x] ModÃ¨le de donnÃ©es normalisÃ© (Pydantic) avec taxonomies riches
- [x] Pipeline : Connector â†’ RawAAP â†’ Normalizer â†’ AAP â†’ AAPCollection
- [x] DÃ©duplication par fingerprint
- [x] Migration Poetry â†’ uv

### âœ… Phase 1 : MVP (Done)

- [x] Stockage Airtable (200+ AAPs actifs)
- [x] Export CSV avec filtres
- [x] Scripts setup Airtable
- [x] Computed fields : `is_active`, `days_remaining`, `urgence`
- [x] Filtres : by_category, by_eligibilite, by_urgence

### ğŸ”„ Phase 1.5 : Enrichissement (En cours)

- [ ] Paris.fr scraping (PDF + LLM) â€” *Walid*
- [ ] Enrichissement LLM (catÃ©gories, tags) via Claude
- [ ] Cron GitHub Actions (collecte quotidienne)
- [ ] Alerte Telegram (nouveaux AAPs)

### ğŸ“‹ Phase 2 : Consolidation

- [ ] Ajouter sources RSS (Profession Banlieue, DRIEETS)
- [ ] Tests unitaires & intÃ©gration
- [ ] UI de consultation (Notion ou web)
- [ ] MÃ©triques (nb AAP/semaine, sources actives)

### ğŸš€ Phase 3 : Expansion

- [ ] Multi-tenant (plusieurs assos)
- [ ] Matching intelligent asso/AAP
- [ ] Scraping fondations privÃ©es

## ğŸ‘¥ Ã‰quipe

- **Younes Ajeddig** â€” DÃ©veloppement, scraping, data model
- **Walid Becherif** â€” Architecture, API IDF, enrichissement LLM

## ğŸ“„ License

MIT
